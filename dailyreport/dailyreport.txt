to do list
・特徴量として、0.5以上の上位の属性を最初に使うことにした
・ガチ勢の特徴量エンジニアリング方法を真似る・調べる・log??
・決定木・ランダムフォレスト

10/9
住宅価格を予測する〜Kaggle House Priceチュートリアルに挑む
https://yolo-kiyoshi.com/2018/12/17/post-1003/


・isnull メソッド？？
    pandasで欠損値NaNが含まれているか判定、個数をカウント
    isnull()で要素ごとに欠損値か判定
    https://note.nkmk.me/python-pandas-nan-judge-count/


・ダミー化？
    文字列でカテゴリー分けされた性別などのデータを、男を0, 女を1のように変換したり、多クラスの特徴量をone-hot表現に変換したりすることができる。機械学習の前処理として行うことが多い。
    https://yuru-d.com/get_dummies/


・対数変換をすることで正規分布に近づけることに、どういう意味がある？？
    https://uribo.github.io/practical-ds/02/numeric.html
    多くのモデルが数値の入力を前提としているため、数値をそのまま利用することもできます。
    しかし特徴量エンジニアリングが不要というわけではありません。 ### 具体的には線形回帰モデルでは、出力から得られる値の誤差が正規分布に従うことを仮定します。
    ### そのため正規分布とは異なる形状の分布をもつデータ、例えば離散値ではその仮定が成立しないことが可能性があります。
    この問題を解決するため、元のデータを正規分布に近似させるという特徴量エンジニアリングが有効になります。


・drop メソッド？
    pandas.DataFrameの行・列を指定して削除するdrop
    ・DataFrameの行を指定して削除
        ー　行名（行ラベル）で指定　
    
    # 学習データ内の分割　train_x = train_.drop('SalePrice',axis=1)


・StandardScaler() : スケール変換
    https://helve-python.hatenablog.jp/entry/scikitlearn-scale-conversion

    この記事では、以下3つのスケール変換方法を扱う。

    StandardScaler: 標準化（平均0, 分散1）
    RobustScaler: 外れ値に頑健な標準化
    MinMaxScaler: 正規化（最大1, 最小0）

    スケール変換は、扱う数値データを何らかの規則で変換するものである。
    機械学習で桁数の異なるデータをまとめて扱うときには、スケール変換がほぼ必須となる。

    （ベーシックな）ニューラルネットワークやSVM（サポートベクターマシン）では、スケール変換をしないとなかなか学習が進まない。
    ただし、ランダムフォレスト等の決定木を使う手法では、スケール変換は不要である。


・Pipeline　パイプライン

    一連の処理ステップをEstimatorとしてまとめることができる。
    ① 標準化 → ② 次元削減 → ③ ランダムフォレストで学習の流れを、グリッドサーチ＋CVで検証する場合の例を記載。

    機械学習ライブラリ scikit-learnの便利機能の紹介
    https://qiita.com/ishizakiiii/items/0650723cc2b4eef2c1cf

・Pass　文
    Pythonのpass文の意味と使い方
    https://note.nkmk.me/python-pass-usage/
    Pythonのpass文は何もしない文であり、文法上なにかを書く必要があるが何も実行することがないときに使う。

・RMSE のスコアの見方？？？
    Lassoのパラメータα=0.01のときに汎化性能が0.18になることがわかりました。
    ちなみに汎化性能は予測結果および教師データに自然対数をかけたものに対し、RMSE(root mean square error)を使って算出しています。
    汎化性能が0.18って良いのかわからない！！